{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5h6FNQ6-S4s",
        "outputId": "02d3dee4-9284-4232-9f59-51566c51ab7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlWG-a1H_lXk",
        "outputId": "68625d3e-5bb1-4305-983a-5e382772b2e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "print(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fySIyGRA_soQ",
        "outputId": "2119d6af-b4e3-48f5-ac87-b80aeaa65c1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No GPUs available.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the list of available GPUs\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "\n",
        "if gpus:\n",
        "    for gpu in gpus:\n",
        "        # Print GPU name and memory details\n",
        "        print(f\"GPU Name: {gpu.name}\")\n",
        "        print(f\"Memory: {tf.config.experimental.get_memory_info(gpu)['total']} MB\")\n",
        "else:\n",
        "    print(\"No GPUs available.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aS2wUuxbAFsd"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# print(tf.__version__)\n",
        "# import tensorflow as tf\n",
        "\n",
        "# # Get the list of available GPUs\n",
        "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "\n",
        "# if gpus:\n",
        "#     for gpu in gpus:\n",
        "#         # Print GPU name and memory details\n",
        "#         print(f\"GPU Name: {gpu.name}\")\n",
        "#         print(f\"Memory: {tf.config.experimental.get_memory_info(gpu)['total']} MB\")\n",
        "# else:\n",
        "#     print(\"No GPUs available.\")\n",
        "\n",
        "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "# if gpus:\n",
        "#     try:\n",
        "#         # Currently, memory growth needs to be the same across GPUs\n",
        "#         for gpu in gpus:\n",
        "#             tf.config.experimental.set_memory_growth(gpu, True)\n",
        "#         logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "#         print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "#     except RuntimeError as e:\n",
        "#         # Memory growth must be set before GPUs have been initialized\n",
        "#         print(e)\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import vgg19\n",
        "\n",
        "# Generated image size\n",
        "RESIZE_HEIGHT = 607\n",
        "\n",
        "NUM_ITER = 3000\n",
        "\n",
        "# Weights of the different loss components\n",
        "CONTENT_WEIGHT = 8e-4 # 8e-4\n",
        "STYLE_WEIGHT = 8e-1 # 8e-4\n",
        "\n",
        "# The layer to use for the content loss.\n",
        "CONTENT_LAYER_NAME = \"block5_conv2\" # \"block2_conv2\"\n",
        "\n",
        "# List of layers to use for the style loss.\n",
        "STYLE_LAYER_NAMES = [\n",
        "    \"block1_conv1\",\n",
        "    \"block2_conv1\",\n",
        "    \"block3_conv1\",\n",
        "    \"block4_conv1\",\n",
        "    \"block5_conv1\",\n",
        "]\n",
        "\n",
        "def get_result_image_size(image_path, result_height):\n",
        "    image_width, image_height = keras.preprocessing.image.load_img(image_path).size\n",
        "    result_width = int(image_width * result_height / image_height)\n",
        "    return result_height, result_width\n",
        "\n",
        "def preprocess_image(image_path, target_height, target_width):\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size = (target_height, target_width))\n",
        "    arr = keras.preprocessing.image.img_to_array(img)\n",
        "    arr = np.expand_dims(arr, axis = 0)\n",
        "    arr = vgg19.preprocess_input(arr)\n",
        "    return tf.convert_to_tensor(arr)\n",
        "\n",
        "def get_model():\n",
        "    # Build a VGG19 model loaded with pre-trained ImageNet weights\n",
        "    model = vgg19.VGG19(weights = 'imagenet', include_top = False)\n",
        "\n",
        "    # Get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
        "    outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
        "\n",
        "    # Set up a model that returns the activation values for every layer in VGG19 (as a dict).\n",
        "    return keras.Model(inputs = model.inputs, outputs = outputs_dict)\n",
        "\n",
        "def get_optimizer():\n",
        "    return keras.optimizers.Adam(\n",
        "        keras.optimizers.schedules.ExponentialDecay(\n",
        "            initial_learning_rate = 24.0, decay_steps = 445, decay_rate = 0.98\n",
        "            # initial_learning_rate = 2.0, decay_steps = 376, decay_rate = 0.98\n",
        "        )\n",
        "    )\n",
        "\n",
        "def compute_loss(feature_extractor, combination_image, content_features, style_features):\n",
        "    combination_features = feature_extractor(combination_image)\n",
        "    loss_content = compute_content_loss(content_features, combination_features)\n",
        "    loss_style = compute_style_loss(style_features, combination_features, combination_image.shape[1] * combination_image.shape[2])\n",
        "\n",
        "    return CONTENT_WEIGHT * loss_content + STYLE_WEIGHT * loss_style\n",
        "\n",
        "# A loss function designed to maintain the 'content' of the original_image in the generated_image\n",
        "def compute_content_loss(content_features, combination_features):\n",
        "    original_image = content_features[CONTENT_LAYER_NAME]\n",
        "    generated_image = combination_features[CONTENT_LAYER_NAME]\n",
        "\n",
        "    return tf.reduce_sum(tf.square(generated_image - original_image)) / 2\n",
        "\n",
        "def compute_style_loss(style_features, combination_features, combination_size):\n",
        "    loss_style = 0\n",
        "\n",
        "    for layer_name in STYLE_LAYER_NAMES:\n",
        "        style_feature = style_features[layer_name][0]\n",
        "        combination_feature = combination_features[layer_name][0]\n",
        "        loss_style += style_loss(style_feature, combination_feature, combination_size) / len(STYLE_LAYER_NAMES)\n",
        "\n",
        "    return loss_style\n",
        "\n",
        "# The \"style loss\" is designed to maintain the style of the reference image in the generated image.\n",
        "# It is based on the gram matrices (which capture style) of feature maps from the style reference image and from the generated image\n",
        "def style_loss(style_features, combination_features, combination_size):\n",
        "    S = gram_matrix(style_features)\n",
        "    C = gram_matrix(combination_features)\n",
        "    channels = style_features.shape[2]\n",
        "    return tf.reduce_sum(tf.square(S - C)) / (4.0 * (channels ** 2) * (combination_size ** 2))\n",
        "\n",
        "def gram_matrix(x):\n",
        "   x = tf.transpose(x, (2, 0, 1))\n",
        "   features = tf.reshape(x, (tf.shape(x)[0], -1))\n",
        "   gram = tf.matmul(features, tf.transpose(features))\n",
        "   return gram\n",
        "\n",
        "def save_result(generated_image, result_height, result_width, name):\n",
        "    img = deprocess_image(generated_image, result_height, result_width)\n",
        "    keras.preprocessing.image.save_img(name, img)\n",
        "\n",
        "# Util function to convert a tensor into a valid image\n",
        "def deprocess_image(tensor, result_height, result_width):\n",
        "    tensor = tensor.numpy()\n",
        "    tensor = tensor.reshape((result_height, result_width, 3))\n",
        "\n",
        "    # Remove zero-center by mean pixel\n",
        "    tensor[:, :, 0] += 103.939\n",
        "    tensor[:, :, 1] += 116.779\n",
        "    tensor[:, :, 2] += 123.680\n",
        "\n",
        "    # 'BGR'->'RGB'\n",
        "    tensor = tensor[:, :, ::-1]\n",
        "    return np.clip(tensor, 0, 255).astype(\"uint8\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Prepare content, stlye images\n",
        "    path = os.path.abspath(os.getcwd())\n",
        "    content_image_path = keras.utils.get_file(path + '\\humber.jpg', 'https://imgur.com/a/RJFfjUJ.jpg')\n",
        "    style_image_path = keras.utils.get_file(path + '\\starry_night.jpg', 'https://i.imgur.com/9ooB60I.jpg')\n",
        "    result_height, result_width = get_result_image_size(content_image_path, RESIZE_HEIGHT)\n",
        "    print(\"result resolution: (%d, %d)\" % (result_height, result_width))\n",
        "\n",
        "    # Preprocessing\n",
        "    content_tensor = preprocess_image(content_image_path, result_height, result_width)\n",
        "    style_tensor = preprocess_image(style_image_path, result_height, result_width)\n",
        "    generated_image = tf.Variable(tf.random.uniform(style_tensor.shape, dtype=tf.dtypes.float32))\n",
        "    # generated_image = tf.Variable(preprocess_image(content_image_path, result_height, result_width))\n",
        "\n",
        "    # Build model\n",
        "    model = get_model()\n",
        "    optimizer = get_optimizer()\n",
        "    print(model.summary())\n",
        "\n",
        "    content_features = model(content_tensor)\n",
        "    style_features = model(style_tensor)\n",
        "\n",
        "    # Optimize result image\n",
        "    for iter in range(NUM_ITER):\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = compute_loss(model, generated_image, content_features, style_features)\n",
        "\n",
        "        grads = tape.gradient(loss, generated_image)\n",
        "\n",
        "        print(\"iter: %4d, loss: %8.f\" % (iter, loss))\n",
        "        optimizer.apply_gradients([(grads, generated_image)])\n",
        "\n",
        "        if (iter + 1) % 100 == 0:\n",
        "            name = \"generated_at_iteration_%d.png\" % (iter + 1)\n",
        "            save_result(generated_image, result_height, result_width, name)\n",
        "\n",
        "    name = \"results/result_%d_%f_%f.png\" % (NUM_ITER, CONTENT_WEIGHT, STYLE_WEIGHT)\n",
        "    save_result(generated_image, result_height, result_width, name)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
